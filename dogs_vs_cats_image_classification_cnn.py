# -*- coding: utf-8 -*-
"""Dogs vs Cats Image Classification - CNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GDI_o6fZGfH7rh9EREP6-zK_9BSvEVWi

## Dataset Information

The training archive contains 25,000 images of dogs and cats. Train your algorithm on these files and predict the labels

(1 = dog, 0 = cat).

## Download Dataset
"""

!wget https://download.microsoft.com/download/3/e/1/3e1c3f21-ecdb-4869-8368-6deba77b919f/kagglecatsanddogs_5340.zip

"""## Unzip the Dataset"""

# !unzip kagglecatsanddogs_3367a.zip
!unzip kagglecatsanddogs_5340.zip

"""## Import Modules"""

# Importing required libraries

import pandas as pd  # Pandas is used for data manipulation and creating DataFrames
import numpy as np  # NumPy is used for numerical computations and array operations
import matplotlib.pyplot as plt  # Matplotlib is used for data visualization (plotting graphs)

import warnings  # Warnings module to manage warning messages
import os  # OS module allows interaction with the operating system (e.g., file handling)
import tqdm  # tqdm is used for creating progress bars in loops
import random  # Random module is used to generate random numbers (e.g., selecting random images)

# Importing load_img from Keras for loading images
from keras.preprocessing.image import load_img  # Used to load images for processing in deep learning models

# Ignoring warnings to keep the output clean
warnings.filterwarnings('ignore')  # Suppresses warning messages to avoid clutter in the output

"""## Create Dataframe for Input and Output"""

# Initializing empty lists to store image file paths and corresponding labels
input_path = []  # List to store the file paths of images
label = []  # List to store labels (0 for Cat, 1 for Dog)

# Loop through each class folder (Cat and Dog) inside the "PetImages" directory
for class_name in os.listdir("PetImages"):
    # Loop through each file in the current class folder
    for path in os.listdir("PetImages/" + class_name):
        # Assign label 0 for Cat images and 1 for Dog images
        if class_name == 'Cat':
            label.append(0)  # Cat images get label 0
        else:
            label.append(1)  # Dog images get label 1

        # Append the full file path of the image to input_path
        input_path.append(os.path.join("PetImages", class_name, path))

# Print the first image file path and its corresponding label
print(input_path[0], label[0])

# Creating an empty DataFrame to store image file paths and their labels
df = pd.DataFrame()

# Assigning the 'images' column with file paths from input_path
df['images'] = input_path

# Assigning the 'label' column with corresponding class labels from label
df['label'] = label

# Shuffling the DataFrame randomly to mix the data
df = df.sample(frac=1).reset_index(drop=True)

# Displaying the first five rows of the DataFrame to verify correctness
df.head()

# Loop through each image file path in the 'images' column of the DataFrame
for i in df['images']:
    # Check if the file extension does not contain '.jpg'
    if '.jpg' not in i:
        # Print the file path if it is not a .jpg file
        print(i)

# Importing the PIL (Pillow) library for image processing
import PIL

# Initializing an empty list to store images that cannot be opened
l = []

# Loop through each image file path in the 'images' column of the DataFrame
for image in df['images']:
    try:
        # Try opening the image using PIL's Image module
        img = PIL.Image.open(image)
    except:
        # If an error occurs (file missing or corrupted), add the file path to the list
        l.append(image)

# Return the list of problematic images
l

# Removing unwanted database files and corrupted images from the DataFrame

# Remove 'Thumbs.db' file from the Dog images folder
df = df[df['images'] != 'PetImages/Dog/Thumbs.db']

# Remove 'Thumbs.db' file from the Cat images folder
df = df[df['images'] != 'PetImages/Cat/Thumbs.db']

# Remove a specific corrupted or unwanted image from the Cat folder
df = df[df['images'] != 'PetImages/Cat/666.jpg']

# Remove a specific corrupted or unwanted image from the Dog folder
df = df[df['images'] != 'PetImages/Dog/11702.jpg']

# Print the total number of remaining images in the dataset
len(df)

"""## Exploratory Data Analysis"""

# Display a grid of 25 randomly selected dog images

# Create a figure with a large size to display images clearly
plt.figure(figsize=(25, 25))

# Filter the dataset to get only images labeled as dogs (label == 1)
temp = df[df['label'] == 1]['images']

# Select a random starting index to pick 25 images
start = random.randint(0, len(temp) - 25)  # Ensure the range is valid

# Select 25 consecutive image file paths from the randomly chosen starting index
files = temp[start:start + 25]

# Loop through the selected images and display them in a 5x5 grid
for index, file in enumerate(files):
    plt.subplot(5, 5, index + 1)  # Create a subplot for each image

    img = load_img(file)  # Load the image from the file path
    img = np.array(img)  # Convert the image to a NumPy array for visualization

    plt.imshow(img)  # Display the image
    plt.title('Dogs')  # Set the title as 'Dogs' for each image
    plt.axis('off')  # Hide axis lines for a cleaner view

# Display a grid of 25 randomly selected cat images

# Create a figure with a large size to display images clearly
plt.figure(figsize=(25, 25))

# Filter the dataset to get only images labeled as cats (label == 0)
temp = df[df['label'] == 0]['images']

# Ensure there are at least 25 cat images to display
if len(temp) < 25:
    print("Not enough cat images available!")
else:
    # Select a random starting index to pick 25 images
    start = random.randint(0, len(temp) - 25)  # Ensures valid range

    # Select 25 consecutive image file paths from the randomly chosen starting index
    files = temp[start:start + 25].tolist()

    # Loop through the selected images and display them in a 5x5 grid
    for index, file in enumerate(files):
        plt.subplot(5, 5, index + 1)  # Create a subplot for each image

        img = load_img(file)  # Load the image from the file path
        img = np.array(img)  # Convert the image to a NumPy array for visualization

        plt.imshow(img)  # Display the image
        plt.title('Cats')  # Set the title as 'Cats' for each image
        plt.axis('off')  # Hide axis lines for a cleaner view

"""## Create DataGenerator for the Images"""

# Convert the 'label' column from integer type to string type
df['label'] = df['label'].astype('str')

df.head()

# Importing train_test_split from scikit-learn to split the dataset
from sklearn.model_selection import train_test_split

# Splitting the dataset into training (80%) and testing (20%) sets
train, test = train_test_split(df, test_size=0.2, random_state=42)

# Importing ImageDataGenerator for data augmentation and preprocessing
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Data augmentation for training images to improve model generalization
train_generator = ImageDataGenerator(
    rescale=1./255,        # Normalize pixel values to range (0, 1)
    rotation_range=40,     # Randomly rotate images up to 40 degrees
    shear_range=0.2,       # Apply shear transformations
    zoom_range=0.2,        # Randomly zoom into images
    horizontal_flip=True,  # Flip images horizontally
    fill_mode='nearest'    # Fill missing pixels after transformation
)

# Only rescale validation images (no augmentation needed, as we only evaluate)
val_generator = ImageDataGenerator(rescale=1./255)

# Creating training data iterator
train_iterator = train_generator.flow_from_dataframe(
    dataframe=train,        # Use the 'train' DataFrame
    x_col='images',         # Column containing image file paths
    y_col='label',          # Column containing class labels (0 = Cat, 1 = Dog)
    target_size=(128, 128), # Resize images to 128x128 pixels
    batch_size=32,          # Number of images per batch (adjust for memory efficiency)
    class_mode='binary'     # Binary classification (Cat vs. Dog)
)

# Creating validation data iterator
val_iterator = val_generator.flow_from_dataframe(
    dataframe=test,         # Use the 'test' DataFrame
    x_col='images',         # Column containing image file paths
    y_col='label',          # Column containing class labels
    target_size=(128, 128), # Resize images to 128x128 pixels
    batch_size=32,          # Number of images per batch
    class_mode='binary'     # Binary classification
)

"""## Model Creation"""

# Import necessary layers from Keras
from keras import Sequential  # Import Sequential model type
from keras.layers import Conv2D, MaxPool2D, Flatten, Dense  # Import essential layers

# Initialize a Sequential model (a stack of layers)
model = Sequential([
    # First convolutional layer with 16 filters, 3x3 kernel size, ReLU activation, and input shape (128x128x3)
    Conv2D(16, (3,3), activation='relu', input_shape=(128,128,3)),

    # First max pooling layer to reduce spatial dimensions
    MaxPool2D((2,2)),

    # Second convolutional layer with 32 filters, 3x3 kernel size, and ReLU activation
    Conv2D(32, (3,3), activation='relu'),

    # Second max pooling layer
    MaxPool2D((2,2)),

    # Third convolutional layer with 64 filters, 3x3 kernel size, and ReLU activation
    Conv2D(64, (3,3), activation='relu'),

    # Third max pooling layer
    MaxPool2D((2,2)),

    # Flatten the feature maps into a 1D array to feed into the fully connected layers
    Flatten(),

    # Fully connected (Dense) layer with 512 neurons and ReLU activation
    Dense(512, activation='relu'),

    # Output layer with a single neuron and sigmoid activation for binary classification (Cat vs Dog)
    Dense(1, activation='sigmoid')
])

# Compile the model with the chosen optimizer, loss function, and evaluation metric
model.compile(
    optimizer='adam',                # Adam optimizer for efficient learning rate adaptation
    loss='binary_crossentropy',      # Binary cross-entropy for binary classification (Cats vs. Dogs)
    metrics=['accuracy']             # Track accuracy as the evaluation metric
)

# Print the model summary to display the architecture
model.summary()

# Train the CNN model using the training dataset and validate it on the test dataset
history = model.fit(
    train_iterator,   # Training dataset iterator
    epochs=10,        # Number of epochs (full passes over the dataset)
    validation_data=val_iterator  # Validation dataset iterator for performance monitoring
)

"""## Visualization of Results"""

# Extract training and validation accuracy from the history object
acc = history.history['accuracy']  # Training accuracy per epoch
val_acc = history.history['val_accuracy']  # Validation accuracy per epoch

# Get the range of epochs (from 0 to total number of epochs)
epochs = range(len(acc))

# Plot the accuracy graph
plt.plot(epochs, acc, 'b', label='Training Accuracy')  # Blue line for training accuracy
plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')  # Red line for validation accuracy
plt.title('Accuracy Graph')  # Set the title of the plot
plt.legend()  # Display the legend to differentiate training and validation curves
plt.figure()  # Create a new figure for the loss graph

# Extract training and validation loss from the history object
loss = history.history['loss']  # Training loss per epoch
val_loss = history.history['val_loss']  # Validation loss per epoch

# Plot the loss graph
plt.plot(epochs, loss, 'b', label='Training Loss')  # Blue line for training loss
plt.plot(epochs, val_loss, 'r', label='Validation Loss')  # Red line for validation loss
plt.title('Loss Graph')  # Set the title of the plot
plt.legend()  # Display the legend to differentiate training and validation curves
plt.show()  # Show the plots

"""## Test with Real Image"""

image_path = "/content/PetImages/Cat/10001.jpg"  # Path of the image

# Load and preprocess the image
img = load_img(image_path, target_size=(128, 128))
img_array = np.array(img) / 255.0  # Normalize the image
img_array = img_array.reshape(1, 128, 128, 3)  # Reshape for prediction

# Make a prediction
pred = model.predict(img_array)

# Determine the label
label = "Dog 🐶" if pred[0] > 0.5 else "Cat 🐱"
print(label)  # Print the label

# ✅ Display the image with the predicted label
plt.imshow(load_img(image_path))
plt.title(f"Predicted: {label}")
plt.axis("off")  # Hide axis
plt.show()

image_path = "/content/PetImages/Dog/10003.jpg"  # Path of the image

# Load and preprocess the image
img = load_img(image_path, target_size=(128, 128))
img_array = np.array(img) / 255.0  # Normalize the image
img_array = img_array.reshape(1, 128, 128, 3)  # Reshape for prediction

# Make a prediction
pred = model.predict(img_array)

# Determine the label
label = "Dog 🐶" if pred[0] > 0.5 else "Cat 🐱"
print(label)  # Print the label

# ✅ Display the image with the predicted label
plt.imshow(load_img(image_path))
plt.title(f"Predicted: {label}")
plt.axis("off")  # Hide axis
plt.show()